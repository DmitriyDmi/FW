----Сразу отмечу, что в архиве нет папки "data" , в которой должны быть 'ga_hits.csv' & 'ga_sessions.csv'
Сдавать архив весом 4.5Гб такое себе.

Файлы get_data_example.py и pipeline.py ссылаются csv из папки 'data', поэтому без данных файлов не будут работать как надо.

----Содержание архива:

final_work.ipynb - начальный документ по решению проблемы и поиску модели, черновик.

get_data_example.py - берет 1 случайную строчку из ga_sessions.csv, 
генерирует json файл на её основе с данными utm_*, device_*, geo_*, и сохраняет в папку 'test'. Используется для теста POST запросов.

main.py - сервис для локального запуска. uvicorn запускается самим файлом.

pipeline.py - пайплайн создания модели на основе данных из 'ga_hits.csv' и 'ga_sessions.csv'.
Можно в итоговую модель прикрепить данные по корреляции признаков, если нужно.
Но я только добавил топ20 значимых фич для модели.
Так же можно добавить топ негативных фич, которые негативно влияют на предикт, если нужно.

----Папка models содержит:
cars_model.pkl - модель без пайплайна. работает только уже на подготовленых данных

pipline.pkl - пайплайн обработки входных данных, содержащий обученную модель и данные о модели.

Структура pipline.pkl:
'model' - пайплайн с моделью
'metadata' - данные о модели
'top_features' - данные о топ20 фичах

-----ЗАПУСК СЕРВИСА-----

1)Запускаем файл main.py
Сервис готов к работе!

2)Открываем POSTMAN

3)Локальный адрес сервиса 127.0.0.1:8000 

4) Поддерживаемые запросы для POSTMAN:
GET - 127.0.0.1:8000/status
GET - 127.0.0.1:8000/version
GET - 127.0.0.1:8000/topfeatures
POST - 127.0.0.1:8000/predict . В body запроса ставим row и вставляем JSON словарь вида {'utm_*':..., 'device_*':..., 'geo_*':...}
